{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exponential smoothing is a time series forecasting method for univariate data that can be extended to support data with a systematic trend or seasonal component."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1 Tutorial Overview\n",
    "This tutorial is divided into five parts; they are: \n",
    "1. Develop a Grid Search Framework\n",
    "2. Case Study 1: No Trend or Seasonality \n",
    "3. Case Study 2: Trend\n",
    "4. Case Study 3: Seasonality\n",
    "5. Case Study 4: Trend and Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.2 Develop a Grid Search Framework\n",
    "We will use the implementation of Holt-Winters Exponential Smoothing provided by the Statsmodels library. This model has hyperparameters that control the nature of the exponential performed for the series, trend, and seasonality, specifically:\n",
    "- smoothing level (alpha): the smoothing coefficient for the level.\n",
    "- smoothing slope (beta): the smoothing coefficient for the trend.\n",
    "- smoothing seasonal (gamma): the smoothing coefficient for the seasonal component. 􏰀 \n",
    "- damping slope (phi): the coefficient for the damped trend.\n",
    "\n",
    "There are other hyperparameters that the model will not automatically tune that you may want to specify; they are:\n",
    "- trend: The type of trend component, as either add for additive or mul for multiplicative. Modeling the trend can be disabled by setting it to None.\n",
    "- damped: Whether or not the trend component should be damped, either True or False.\n",
    "- seasonal: The type of seasonal component, as either add for additive or mul for multiplicative. Modeling the seasonal component can be disabled by setting it to None.\n",
    "- seasonal periods: The number of time steps in a seasonal period, e.g. 12 for 12 months in a yearly seasonal structure.\n",
    "- use boxcox: Whether or not to perform a power transform of the series (True/False) or specify the lambda for the transform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start-off by defining a function that will fit a model with a given configuration and make a one-step forecast. \n",
    "- The __exp_smoothing_forecast()__ below implements this behavior. The function takes an array or list of contiguous prior observations and a list of configuration parameters used to configure the model. The configuration parameters in order are: the trend type, the dampening type, the seasonality type, the seasonal period, whether or not to use a Box-Cox transform, and whether or not to remove the bias when fitting the model.\n",
    "\n",
    "- we will use the grid searching framework developed in Chapter 11 for tuning and evaluating naive forecasting methods. One important modification to the framework is the function used to perform the walk-forward validation of the model named __walk_forward_validation()__. This function must be updated to call the function for making an ETS forecast.\n",
    "\n",
    "- The only parameter we may want to specify is the periodicity of the seasonal component in the series, if one exists. By default, we will assume no seasonal component. The __exp_smoothing_configs()__ function below will create a list of model configurations to evaluate. An optional list of seasonal periods can be specified, and you could even change the function to specify other elements that you may know about your time series. In theory, there are 72 possible model configurations to evaluate, but in practice, many will not be valid and will result in an error that we will trap and ignore.\n",
    "\n",
    "- We now have a framework for grid searching triple exponential smoothing model hyperpa- rameters via one-step walk-forward validation. It is generic and will work for any in-memory univariate time series provided as a list or NumPy array. We can make sure all the pieces work together by testing it on a contrived 10-step dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
      " > Model[[None, False, None, None, True, True]] 1.380\n",
      " > Model[[None, False, None, None, True, False]] 10.000\n",
      " > Model[[None, False, None, None, False, True]] 2.563\n",
      " > Model[[None, False, None, None, False, False]] 10.000\n",
      "done\n",
      "[None, False, None, None, True, True] 1.379824445857423\n",
      "[None, False, None, None, False, True] 2.5628662672606612\n",
      "[None, False, None, None, False, False] 10.0\n"
     ]
    }
   ],
   "source": [
    "# grid search holt winter's exponential smoothing\n",
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# one-step Holt Winter’s Exponential Smoothing forecast\n",
    "def exp_smoothing_forecast(history, config):\n",
    "\tt,d,s,p,b,r = config\n",
    "\t# define model\n",
    "\tmodel = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "\t# fit model\n",
    "\tmodel_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "\t# make one step forecast\n",
    "\tyhat = model_fit.predict(len(history), len(history))\n",
    "\treturn yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = exp_smoothing_forecast(history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\treturn error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "\tresult = None\n",
    "\t# convert config to a key\n",
    "\tkey = str(cfg)\n",
    "\t# show all warnings and fail on exception if debugging\n",
    "\tif debug:\n",
    "\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\telse:\n",
    "\t\t# one failure during model validation suggests an unstable config\n",
    "\t\ttry:\n",
    "\t\t\t# never show warnings when grid searching, too noisy\n",
    "\t\t\twith catch_warnings():\n",
    "\t\t\t\tfilterwarnings(\"ignore\")\n",
    "\t\t\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\t\texcept:\n",
    "\t\t\terror = None\n",
    "\t# check for an interesting result\n",
    "\tif result is not None:\n",
    "\t\tprint(' > Model[%s] %.3f' % (key, result))\n",
    "\treturn (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "\tscores = None\n",
    "\tif parallel:\n",
    "\t\t# execute configs in parallel\n",
    "\t\texecutor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "\t\ttasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "\t\tscores = executor(tasks)\n",
    "\telse:\n",
    "\t\tscores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "\t# remove empty results\n",
    "\tscores = [r for r in scores if r[1] != None]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]):\n",
    "\tmodels = list()\n",
    "\t# define config lists\n",
    "\tt_params = ['add', 'mul', None]\n",
    "\td_params = [True, False]\n",
    "\ts_params = ['add', 'mul', None]\n",
    "\tp_params = seasonal\n",
    "\tb_params = [True, False]\n",
    "\tr_params = [True, False]\n",
    "\t# create config instances\n",
    "\tfor t in t_params:\n",
    "\t\tfor d in d_params:\n",
    "\t\t\tfor s in s_params:\n",
    "\t\t\t\tfor p in p_params:\n",
    "\t\t\t\t\tfor b in b_params:\n",
    "\t\t\t\t\t\tfor r in r_params:\n",
    "\t\t\t\t\t\t\tcfg = [t,d,s,p,b,r]\n",
    "\t\t\t\t\t\t\tmodels.append(cfg)\n",
    "\treturn models\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# define dataset\n",
    "\tdata = [10.0, 20.0, 30.0, 40.0, 50.0, 60.0, 70.0, 80.0, 90.0, 100.0]\n",
    "\tprint(data)\n",
    "\t# data split\n",
    "\tn_test = 4\n",
    "\t# model configs\n",
    "\tcfg_list = exp_smoothing_configs()\n",
    "\t# grid search\n",
    "\tscores = grid_search(data, cfg_list, n_test)\n",
    "\tprint('done')\n",
    "\t# list top 3 configs\n",
    "\tfor cfg, error in scores[:3]:\n",
    "\t\tprint(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not report the model parameters optimized by the model itself. It is assumed that you can achieve the same result again by specifying the broader hyperparameters and allow the library to find the same internal parameters. You can access these internal parameters by refitting a standalone model with the same configuration and printing the contents of the params attribute on the model fit; for example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.3 Case Study 1: No Trend or Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The daily female births dataset summarizes the daily total female births in California, USA in 1959."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model[[None, False, None, None, True, True]] 7.169\n",
      " > Model[[None, False, None, None, True, False]] 7.212\n",
      " > Model[[None, False, None, None, False, True]] 7.117\n",
      " > Model[[None, False, None, None, False, False]] 7.126\n",
      " > Model[['add', True, None, None, True, True]] 7.118\n",
      " > Model[['add', True, None, None, True, False]] 7.170\n",
      " > Model[['add', True, None, None, False, True]] 7.113\n",
      " > Model[['add', True, None, None, False, False]] 7.126\n",
      " > Model[['add', False, None, None, True, True]] 7.064\n",
      " > Model[['add', False, None, None, True, False]] 7.103\n",
      " > Model[['add', False, None, None, False, True]] 7.129\n",
      " > Model[['add', False, None, None, False, False]] 7.122\n",
      "done\n",
      "['add', False, None, None, True, True] 7.063624026364671\n",
      "['add', False, None, None, True, False] 7.1027773049078\n",
      "['add', True, None, None, False, True] 7.112743293354173\n"
     ]
    }
   ],
   "source": [
    "# grid search ets models for daily female births\n",
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "\n",
    "# one-step Holt Winter’s Exponential Smoothing forecast\n",
    "def exp_smoothing_forecast(history, config):\n",
    "\tt,d,s,p,b,r = config\n",
    "\t# define model\n",
    "\tmodel = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "\t# fit model\n",
    "\tmodel_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "\t# make one step forecast\n",
    "\tyhat = model_fit.predict(len(history), len(history))\n",
    "\treturn yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = exp_smoothing_forecast(history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\treturn error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "\tresult = None\n",
    "\t# convert config to a key\n",
    "\tkey = str(cfg)\n",
    "\t# show all warnings and fail on exception if debugging\n",
    "\tif debug:\n",
    "\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\telse:\n",
    "\t\t# one failure during model validation suggests an unstable config\n",
    "\t\ttry:\n",
    "\t\t\t# never show warnings when grid searching, too noisy\n",
    "\t\t\twith catch_warnings():\n",
    "\t\t\t\tfilterwarnings(\"ignore\")\n",
    "\t\t\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\t\texcept:\n",
    "\t\t\terror = None\n",
    "\t# check for an interesting result\n",
    "\tif result is not None:\n",
    "\t\tprint(' > Model[%s] %.3f' % (key, result))\n",
    "\treturn (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "\tscores = None\n",
    "\tif parallel:\n",
    "\t\t# execute configs in parallel\n",
    "\t\texecutor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "\t\ttasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "\t\tscores = executor(tasks)\n",
    "\telse:\n",
    "\t\tscores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "\t# remove empty results\n",
    "\tscores = [r for r in scores if r[1] != None]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]):\n",
    "\tmodels = list()\n",
    "\t# define config lists\n",
    "\tt_params = ['add', 'mul', None]\n",
    "\td_params = [True, False]\n",
    "\ts_params = ['add', 'mul', None]\n",
    "\tp_params = seasonal\n",
    "\tb_params = [True, False]\n",
    "\tr_params = [True, False]\n",
    "\t# create config instances\n",
    "\tfor t in t_params:\n",
    "\t\tfor d in d_params:\n",
    "\t\t\tfor s in s_params:\n",
    "\t\t\t\tfor p in p_params:\n",
    "\t\t\t\t\tfor b in b_params:\n",
    "\t\t\t\t\t\tfor r in r_params:\n",
    "\t\t\t\t\t\t\tcfg = [t,d,s,p,b,r]\n",
    "\t\t\t\t\t\t\tmodels.append(cfg)\n",
    "\treturn models\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# load dataset\n",
    "\tseries = read_csv('daily-total-female-births.csv', header=0, index_col=0)\n",
    "\tdata = series.values\n",
    "\t# data split\n",
    "\tn_test = 165\n",
    "\t# model configs\n",
    "\tcfg_list = exp_smoothing_configs()\n",
    "\t# grid search\n",
    "\tscores = grid_search(data, cfg_list, n_test)\n",
    "\tprint('done')\n",
    "\t# list top 3 configs\n",
    "\tfor cfg, error in scores[:3]:\n",
    "\t\tprint(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best result was an RMSE of about 7.06 births. A naive model achieved an RMSE of 6.93 births, meaning that the best performing ETS model is not skillful on this problem. We can unpack the configuration of the best performing model as follows:\n",
    "- Trend: Additive\n",
    "- Damped: False\n",
    "- Seasonal: None\n",
    "- Seasonal Periods: None\n",
    "- Box-Cox Transform: True 􏰀 \n",
    "- Remove Bias: True\n",
    "\n",
    "What is surprising is that a model that assumed an additive trend performed better than one that didn’t. We would not know that this is the case unless we threw out assumptions and grid searched models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.4 Case Study 2: Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monthly shampoo sales dataset summarizes the monthly sales of shampoo over a three-year period. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model[[None, False, None, None, False, True]] 99.415\n",
      " > Model[[None, False, None, None, False, False]] 108.031\n",
      " > Model[['add', True, None, None, False, True]] 97.918\n",
      " > Model[['add', True, None, None, False, False]] 103.069\n",
      " > Model[['add', False, None, None, False, True]] 106.431\n",
      " > Model[['add', False, None, None, False, False]] 104.874\n",
      "done\n",
      "['add', True, None, None, False, True] 97.91815887250195\n",
      "[None, False, None, None, False, True] 99.41548954854885\n",
      "['add', True, None, None, False, False] 103.0687814016001\n"
     ]
    }
   ],
   "source": [
    "# grid search ets models for monthly shampoo sales\n",
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "\n",
    "# one-step Holt Winter’s Exponential Smoothing forecast\n",
    "def exp_smoothing_forecast(history, config):\n",
    "\tt,d,s,p,b,r = config\n",
    "\t# define model\n",
    "\tmodel = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "\t# fit model\n",
    "\tmodel_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "\t# make one step forecast\n",
    "\tyhat = model_fit.predict(len(history), len(history))\n",
    "\treturn yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = exp_smoothing_forecast(history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\treturn error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "\tresult = None\n",
    "\t# convert config to a key\n",
    "\tkey = str(cfg)\n",
    "\t# show all warnings and fail on exception if debugging\n",
    "\tif debug:\n",
    "\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\telse:\n",
    "\t\t# one failure during model validation suggests an unstable config\n",
    "\t\ttry:\n",
    "\t\t\t# never show warnings when grid searching, too noisy\n",
    "\t\t\twith catch_warnings():\n",
    "\t\t\t\tfilterwarnings(\"ignore\")\n",
    "\t\t\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\t\texcept:\n",
    "\t\t\terror = None\n",
    "\t# check for an interesting result\n",
    "\tif result is not None:\n",
    "\t\tprint(' > Model[%s] %.3f' % (key, result))\n",
    "\treturn (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "\tscores = None\n",
    "\tif parallel:\n",
    "\t\t# execute configs in parallel\n",
    "\t\texecutor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "\t\ttasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "\t\tscores = executor(tasks)\n",
    "\telse:\n",
    "\t\tscores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "\t# remove empty results\n",
    "\tscores = [r for r in scores if r[1] != None]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]):\n",
    "\tmodels = list()\n",
    "\t# define config lists\n",
    "\tt_params = ['add', 'mul', None]\n",
    "\td_params = [True, False]\n",
    "\ts_params = ['add', 'mul', None]\n",
    "\tp_params = seasonal\n",
    "\tb_params = [True, False]\n",
    "\tr_params = [True, False]\n",
    "\t# create config instances\n",
    "\tfor t in t_params:\n",
    "\t\tfor d in d_params:\n",
    "\t\t\tfor s in s_params:\n",
    "\t\t\t\tfor p in p_params:\n",
    "\t\t\t\t\tfor b in b_params:\n",
    "\t\t\t\t\t\tfor r in r_params:\n",
    "\t\t\t\t\t\t\tcfg = [t,d,s,p,b,r]\n",
    "\t\t\t\t\t\t\tmodels.append(cfg)\n",
    "\treturn models\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# load dataset\n",
    "\tseries = read_csv('monthly-shampoo-sales.csv', header=0, index_col=0)\n",
    "\tdata = series.values\n",
    "\t# data split\n",
    "\tn_test = 12\n",
    "\t# model configs\n",
    "\tcfg_list = exp_smoothing_configs()\n",
    "\t# grid search\n",
    "\tscores = grid_search(data, cfg_list, n_test)\n",
    "\tprint('done')\n",
    "\t# list top 3 configs\n",
    "\tfor cfg, error in scores[:3]:\n",
    "\t\tprint(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best result was an RMSE of about 97.91 sales. A naive model achieved an RMSE of 95.69 sales on this dataset, meaning that the best performing ETS model is not skillful on this problem. We can unpack the configuration of the best performing model as follows:\n",
    "- Trend: Additive\n",
    "- Damped: False\n",
    "- Seasonal: None\n",
    "- Seasonal Periods: None\n",
    "- Box-Cox Transform: False 􏰀 \n",
    "- Remove Bias: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.5 Case Study 3: Seasonality\n",
    "The monthly mean temperatures dataset summarizes the monthly average air temperatures in Nottingham Castle, England from 1920 to 1939 in degrees Fahrenheit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the file with the filename monthly-mean-temp.csv in your current working directory. The dataset has 20 years, or 240 observations. We will trim the dataset to the last five years of data (60 observations) in order to speed up the model evaluation process and use the last year or 12 observations for the test set.\n",
    "- The period of the seasonal component is about one year, or 12 observations. We will use this as the seasonal period in the call to the exp smoothing configs() function when preparing the model configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model[['add', True, 'add', 12, True, True]] 1.646\n",
      " > Model[['add', True, 'add', 12, False, True]] 1.568\n",
      " > Model[['add', True, 'add', 12, False, False]] 1.555\n",
      " > Model[['add', True, 'add', 12, True, False]] 1.638\n",
      " > Model[['add', True, None, 0, True, True]] 4.654\n",
      " > Model[[None, False, 'add', 12, True, True]] 1.508\n",
      " > Model[['add', True, None, 0, True, False]] 4.597\n",
      " > Model[[None, False, 'add', 12, True, False]] 1.507\n",
      " > Model[['add', True, None, 0, False, True]] 4.800\n",
      " > Model[[None, False, 'add', 12, False, True]] 1.502\n",
      " > Model[['add', True, None, 0, False, False]] 4.760\n",
      " > Model[[None, False, 'add', 12, False, False]] 1.502\n",
      " > Model[[None, False, None, 0, True, True]] 5.188\n",
      " > Model[[None, False, None, 0, True, False]] 5.143\n",
      " > Model[[None, False, None, 0, False, True]] 5.187\n",
      " > Model[[None, False, None, 0, False, False]] 5.143\n",
      " > Model[[None, False, None, 12, True, True]] 5.188\n",
      " > Model[[None, False, None, 12, True, False]] 5.143\n",
      " > Model[[None, False, None, 12, False, True]] 5.187\n",
      " > Model[[None, False, None, 12, False, False]] 5.143\n",
      " > Model[['add', True, None, 12, True, True]] 4.654\n",
      " > Model[['add', True, None, 12, True, False]] 4.597\n",
      " > Model[['add', True, None, 12, False, True]] 4.800\n",
      " > Model[['add', True, None, 12, False, False]] 4.760\n",
      " > Model[['add', False, 'add', 12, True, True]] 1.851\n",
      " > Model[['add', False, 'add', 12, True, False]] 1.820\n",
      " > Model[['add', False, 'add', 12, False, True]] 1.732\n",
      " > Model[['add', False, 'add', 12, False, False]] 1.693\n",
      " > Model[['add', False, None, 0, True, True]] 4.975\n",
      " > Model[['add', False, None, 0, True, False]] 4.894\n",
      " > Model[['add', False, None, 0, False, True]] 5.203\n",
      " > Model[['add', False, None, 0, False, False]] 5.151\n",
      " > Model[['add', False, None, 12, True, True]] 4.975\n",
      " > Model[['add', False, None, 12, True, False]] 4.894\n",
      " > Model[['add', False, None, 12, False, True]] 5.203\n",
      " > Model[['add', False, None, 12, False, False]] 5.151\n",
      "done\n",
      "[None, False, 'add', 12, False, True] 1.50157005787443\n",
      "[None, False, 'add', 12, False, False] 1.50157023959645\n",
      "[None, False, 'add', 12, True, False] 1.5072135770611232\n"
     ]
    }
   ],
   "source": [
    "# grid search ets hyperparameters for monthly mean temp dataset\n",
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "\n",
    "# one-step Holt Winter’s Exponential Smoothing forecast\n",
    "def exp_smoothing_forecast(history, config):\n",
    "\tt,d,s,p,b,r = config\n",
    "\t# define model\n",
    "\tmodel = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "\t# fit model\n",
    "\tmodel_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "\t# make one step forecast\n",
    "\tyhat = model_fit.predict(len(history), len(history))\n",
    "\treturn yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = exp_smoothing_forecast(history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\treturn error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "\tresult = None\n",
    "\t# convert config to a key\n",
    "\tkey = str(cfg)\n",
    "\t# show all warnings and fail on exception if debugging\n",
    "\tif debug:\n",
    "\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\telse:\n",
    "\t\t# one failure during model validation suggests an unstable config\n",
    "\t\ttry:\n",
    "\t\t\t# never show warnings when grid searching, too noisy\n",
    "\t\t\twith catch_warnings():\n",
    "\t\t\t\tfilterwarnings(\"ignore\")\n",
    "\t\t\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\t\texcept:\n",
    "\t\t\terror = None\n",
    "\t# check for an interesting result\n",
    "\tif result is not None:\n",
    "\t\tprint(' > Model[%s] %.3f' % (key, result))\n",
    "\treturn (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "\tscores = None\n",
    "\tif parallel:\n",
    "\t\t# execute configs in parallel\n",
    "\t\texecutor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "\t\ttasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "\t\tscores = executor(tasks)\n",
    "\telse:\n",
    "\t\tscores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "\t# remove empty results\n",
    "\tscores = [r for r in scores if r[1] != None]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]):\n",
    "\tmodels = list()\n",
    "\t# define config lists\n",
    "\tt_params = ['add', 'mul', None]\n",
    "\td_params = [True, False]\n",
    "\ts_params = ['add', 'mul', None]\n",
    "\tp_params = seasonal\n",
    "\tb_params = [True, False]\n",
    "\tr_params = [True, False]\n",
    "\t# create config instances\n",
    "\tfor t in t_params:\n",
    "\t\tfor d in d_params:\n",
    "\t\t\tfor s in s_params:\n",
    "\t\t\t\tfor p in p_params:\n",
    "\t\t\t\t\tfor b in b_params:\n",
    "\t\t\t\t\t\tfor r in r_params:\n",
    "\t\t\t\t\t\t\tcfg = [t,d,s,p,b,r]\n",
    "\t\t\t\t\t\t\tmodels.append(cfg)\n",
    "\treturn models\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# load dataset\n",
    "\tseries = read_csv('monthly-mean-temp.csv', header=0, index_col=0)\n",
    "\tdata = series.values\n",
    "\t# trim dataset to 5 years\n",
    "\tdata = data[-(5*12):]\n",
    "\t# data split\n",
    "\tn_test = 12\n",
    "\t# model configs\n",
    "\tcfg_list = exp_smoothing_configs(seasonal=[0,12])\n",
    "\t# grid search\n",
    "\tscores = grid_search(data, cfg_list, n_test)\n",
    "\tprint('done')\n",
    "\t# list top 3 configs\n",
    "\tfor cfg, error in scores[:3]:\n",
    "\t\tprint(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best result was an RMSE of about 1.50 degrees. This is the same RMSE found by a naive model on this problem, suggesting that the best ETS model sits on the border of being unskillful. We can unpack the configuration of the best performing model as follows:\n",
    "- Trend: None\n",
    "- Damped: False\n",
    "- Seasonal: Additive\n",
    "- Seasonal Periods: 12\n",
    "- Box-Cox Transform: False 􏰀 \n",
    "- Remove Bias: True "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.6 Case Study 4: Trend and Seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The monthly car sales dataset summarizes the monthly car sales in Quebec, Canada between 1960 and 1968. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset has 9 years, or 108 observations. We will use the last year or 12 observations as the test set. The period of the seasonal component could be six months or 12 months. \n",
    "- We will try both as the seasonal period in the call to the exp smoothing configs() function when preparing the model configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Model[['add', True, 'add', 6, False, False]] 3226.384\n",
      " > Model[['add', True, 'add', 6, False, True]] 3240.433\n",
      " > Model[['add', True, 'add', 6, True, False]] 2792.320\n",
      " > Model[['add', True, 'add', 6, True, True]] 2793.930\n",
      " > Model[[None, False, 'add', 6, True, True]] 3204.874\n",
      " > Model[[None, False, 'add', 6, True, False]] 3190.972\n",
      " > Model[[None, False, 'add', 6, False, True]] 3147.646\n",
      " > Model[[None, False, 'add', 6, False, False]] 3133.359\n",
      " > Model[[None, False, 'add', 12, True, True]] 1834.934\n",
      " > Model[[None, False, 'add', 12, True, False]] 1872.137\n",
      " > Model[[None, False, 'add', 12, False, True]] 1799.253\n",
      " > Model[[None, False, 'add', 12, False, False]] 1836.023\n",
      " > Model[[None, False, None, 0, True, True]] 3801.741\n",
      " > Model[[None, False, None, 0, True, False]] 3783.966\n",
      " > Model[[None, False, None, 0, False, True]] 3801.560\n",
      " > Model[[None, False, None, 0, False, False]] 3783.966\n",
      " > Model[[None, False, None, 6, True, True]] 3801.741\n",
      " > Model[[None, False, None, 6, True, False]] 3783.966\n",
      " > Model[[None, False, None, 6, False, True]] 3801.560\n",
      " > Model[[None, False, None, 6, False, False]] 3783.966\n",
      " > Model[[None, False, None, 12, True, True]] 3801.741\n",
      " > Model[[None, False, None, 12, True, False]] 3783.966\n",
      " > Model[[None, False, None, 12, False, True]] 3801.560\n",
      " > Model[[None, False, None, 12, False, False]] 3783.966\n",
      " > Model[['add', True, 'add', 12, True, True]] 2144.481\n",
      " > Model[['add', True, 'add', 12, True, False]] 2135.122\n",
      " > Model[['add', True, 'add', 12, False, True]] 1667.413\n",
      " > Model[['add', True, 'add', 12, False, False]] 1657.834\n",
      " > Model[['add', True, None, 0, True, True]] 3935.661\n",
      " > Model[['add', True, None, 0, True, False]] 3915.499\n",
      " > Model[['add', True, None, 0, False, True]] 3924.448\n",
      " > Model[['add', True, None, 0, False, False]] 3905.417\n",
      " > Model[['add', True, None, 6, True, True]] 3935.661\n",
      " > Model[['add', True, None, 6, True, False]] 3915.499\n",
      " > Model[['add', True, None, 6, False, True]] 3924.448\n",
      " > Model[['add', True, None, 6, False, False]] 3905.417\n",
      " > Model[['add', True, None, 12, True, True]] 3935.661\n",
      " > Model[['add', True, None, 12, True, False]] 3915.499\n",
      " > Model[['add', True, None, 12, False, True]] 3924.448\n",
      " > Model[['add', True, None, 12, False, False]] 3905.417\n",
      " > Model[['add', False, 'add', 6, True, True]] 3220.532\n",
      " > Model[['add', False, 'add', 6, True, False]] 3199.766\n",
      " > Model[['add', False, 'add', 6, False, True]] 3243.478\n",
      " > Model[['add', False, 'add', 6, False, False]] 3226.955\n",
      " > Model[['add', False, 'add', 12, True, True]] 1833.532\n",
      " > Model[['add', False, 'add', 12, True, False]] 1833.656\n",
      " > Model[['add', False, 'add', 12, False, True]] 1723.628\n",
      " > Model[['add', False, 'add', 12, False, False]] 1721.241\n",
      " > Model[['add', False, None, 0, True, True]] 3815.765\n",
      " > Model[['add', False, None, 0, True, False]] 3813.234\n",
      " > Model[['add', False, None, 0, False, True]] 3807.512\n",
      " > Model[['add', False, None, 0, False, False]] 3818.654\n",
      " > Model[['add', False, None, 6, True, True]] 3815.765\n",
      " > Model[['add', False, None, 6, True, False]] 3813.234\n",
      " > Model[['add', False, None, 6, False, True]] 3807.512\n",
      " > Model[['add', False, None, 6, False, False]] 3818.654\n",
      " > Model[['add', False, None, 12, True, True]] 3815.765\n",
      " > Model[['add', False, None, 12, True, False]] 3813.234\n",
      " > Model[['add', False, None, 12, False, True]] 3807.512\n",
      " > Model[['add', False, None, 12, False, False]] 3818.654\n",
      "done\n",
      "['add', True, 'add', 12, False, False] 1657.8341229906548\n",
      "['add', True, 'add', 12, False, True] 1667.412575110055\n",
      "['add', False, 'add', 12, False, False] 1721.240856055638\n"
     ]
    }
   ],
   "source": [
    "# grid search ets models for monthly car sales\n",
    "from math import sqrt\n",
    "from multiprocessing import cpu_count\n",
    "from joblib import Parallel\n",
    "from joblib import delayed\n",
    "from warnings import catch_warnings\n",
    "from warnings import filterwarnings\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import read_csv\n",
    "\n",
    "# one-step Holt Winter’s Exponential Smoothing forecast\n",
    "def exp_smoothing_forecast(history, config):\n",
    "\tt,d,s,p,b,r = config\n",
    "\t# define model\n",
    "\tmodel = ExponentialSmoothing(history, trend=t, damped=d, seasonal=s, seasonal_periods=p)\n",
    "\t# fit model\n",
    "\tmodel_fit = model.fit(optimized=True, use_boxcox=b, remove_bias=r)\n",
    "\t# make one step forecast\n",
    "\tyhat = model_fit.predict(len(history), len(history))\n",
    "\treturn yhat[0]\n",
    "\n",
    "# root mean squared error or rmse\n",
    "def measure_rmse(actual, predicted):\n",
    "\treturn sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# split a univariate dataset into train/test sets\n",
    "def train_test_split(data, n_test):\n",
    "\treturn data[:-n_test], data[-n_test:]\n",
    "\n",
    "# walk-forward validation for univariate data\n",
    "def walk_forward_validation(data, n_test, cfg):\n",
    "\tpredictions = list()\n",
    "\t# split dataset\n",
    "\ttrain, test = train_test_split(data, n_test)\n",
    "\t# seed history with training dataset\n",
    "\thistory = [x for x in train]\n",
    "\t# step over each time-step in the test set\n",
    "\tfor i in range(len(test)):\n",
    "\t\t# fit model and make forecast for history\n",
    "\t\tyhat = exp_smoothing_forecast(history, cfg)\n",
    "\t\t# store forecast in list of predictions\n",
    "\t\tpredictions.append(yhat)\n",
    "\t\t# add actual observation to history for the next loop\n",
    "\t\thistory.append(test[i])\n",
    "\t# estimate prediction error\n",
    "\terror = measure_rmse(test, predictions)\n",
    "\treturn error\n",
    "\n",
    "# score a model, return None on failure\n",
    "def score_model(data, n_test, cfg, debug=False):\n",
    "\tresult = None\n",
    "\t# convert config to a key\n",
    "\tkey = str(cfg)\n",
    "\t# show all warnings and fail on exception if debugging\n",
    "\tif debug:\n",
    "\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\telse:\n",
    "\t\t# one failure during model validation suggests an unstable config\n",
    "\t\ttry:\n",
    "\t\t\t# never show warnings when grid searching, too noisy\n",
    "\t\t\twith catch_warnings():\n",
    "\t\t\t\tfilterwarnings(\"ignore\")\n",
    "\t\t\t\tresult = walk_forward_validation(data, n_test, cfg)\n",
    "\t\texcept:\n",
    "\t\t\terror = None\n",
    "\t# check for an interesting result\n",
    "\tif result is not None:\n",
    "\t\tprint(' > Model[%s] %.3f' % (key, result))\n",
    "\treturn (key, result)\n",
    "\n",
    "# grid search configs\n",
    "def grid_search(data, cfg_list, n_test, parallel=True):\n",
    "\tscores = None\n",
    "\tif parallel:\n",
    "\t\t# execute configs in parallel\n",
    "\t\texecutor = Parallel(n_jobs=cpu_count(), backend='multiprocessing')\n",
    "\t\ttasks = (delayed(score_model)(data, n_test, cfg) for cfg in cfg_list)\n",
    "\t\tscores = executor(tasks)\n",
    "\telse:\n",
    "\t\tscores = [score_model(data, n_test, cfg) for cfg in cfg_list]\n",
    "\t# remove empty results\n",
    "\tscores = [r for r in scores if r[1] != None]\n",
    "\t# sort configs by error, asc\n",
    "\tscores.sort(key=lambda tup: tup[1])\n",
    "\treturn scores\n",
    "\n",
    "# create a set of exponential smoothing configs to try\n",
    "def exp_smoothing_configs(seasonal=[None]):\n",
    "\tmodels = list()\n",
    "\t# define config lists\n",
    "\tt_params = ['add', 'mul', None]\n",
    "\td_params = [True, False]\n",
    "\ts_params = ['add', 'mul', None]\n",
    "\tp_params = seasonal\n",
    "\tb_params = [True, False]\n",
    "\tr_params = [True, False]\n",
    "\t# create config instances\n",
    "\tfor t in t_params:\n",
    "\t\tfor d in d_params:\n",
    "\t\t\tfor s in s_params:\n",
    "\t\t\t\tfor p in p_params:\n",
    "\t\t\t\t\tfor b in b_params:\n",
    "\t\t\t\t\t\tfor r in r_params:\n",
    "\t\t\t\t\t\t\tcfg = [t,d,s,p,b,r]\n",
    "\t\t\t\t\t\t\tmodels.append(cfg)\n",
    "\treturn models\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\t# load dataset\n",
    "\tseries = read_csv('monthly-car-sales.csv', header=0, index_col=0)\n",
    "\tdata = series.values\n",
    "\t# data split\n",
    "\tn_test = 12\n",
    "\t# model configs\n",
    "\tcfg_list = exp_smoothing_configs(seasonal=[0,6,12])\n",
    "\t# grid search\n",
    "\tscores = grid_search(data, cfg_list, n_test)\n",
    "\tprint('done')\n",
    "\t# list top 3 configs\n",
    "\tfor cfg, error in scores[:3]:\n",
    "\t\tprint(cfg, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best result was an RMSE of about 1,657 sales. A naive model achieved an RMSE of 1841.15 sales on this problem, suggesting that the best performing ETS model is skillful. We can unpack the configuration of the best performing model as follows:\n",
    "- Trend: Additive\n",
    "- Damped: True\n",
    "- Seasonal: Additive\n",
    "- Seasonal Periods: 12\n",
    "- Box-Cox Transform: False 􏰀 \n",
    "- Remove Bias: True\n",
    "This is a little surprising as I would have guessed that a six-month seasonal model would be the preferred approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.8 Further Reading\n",
    "This section provides more resources on the topic if you are looking to go deeper.\n",
    "\n",
    "### 12.8.1 Books\n",
    "- Chapter 7 Exponential smoothing, Forecasting: principles and practice, 2013. https://amzn.to/2xlJsfV\n",
    "- Section 6.4. Introduction to Time Series Analysis, Engineering Statistics Handbook, 2012. https://www.itl.nist.gov/div898/handbook/\n",
    "- Practical Time Series Forecasting with R, 2016. https://amzn.to/2LGKzKm\n",
    "\n",
    "### 12.8.2 APIs\n",
    "- statsmodels.tsa.holtwinters.ExponentialSmoothing API.\n",
    "- statsmodels.tsa.holtwinters.HoltWintersResults API.\n",
    "\n",
    "### 12.8.3 Articles\n",
    "- Exponential smoothing, Wikipedia. https://en.wikipedia.org/wiki/Exponential_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.9 Summary\n",
    "In this tutorial, you discovered how to develop a framework for grid searching all of the exponential smoothing model hyperparameters for univariate time series forecasting. Specifically, you learned:\n",
    "- How to develop a framework for grid searching ETS models from scratch using walk-forward validation.\n",
    "- How to grid search ETS model hyperparameters for daily time series data for births.\n",
    "- How to grid search ETS model hyperparameters for monthly time series data for shampoo sales, car sales and temperature."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
